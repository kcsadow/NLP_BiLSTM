{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiLSTM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y0RFwmQkD-VC"},"source":["# Set up"]},{"cell_type":"markdown","metadata":{"id":"gMw3z-nbED5V"},"source":["## Mounting Drive to Access Data Files"]},{"cell_type":"code","metadata":{"id":"BKuTb2_4hHX6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618943920770,"user_tz":240,"elapsed":19074,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"45785f38-6062-4c21-80b0-7face845766d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","#drive_folder = \"gdrive/My Drive/CS6741 Replication Project/\" # Katherine\n","drive_folder = \"gdrive/My Drive/CS6741 - Topics in Natural Language Processing and Machine Learning/CS6741 Replication Project/\" # Linda"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0g6h3t_QEF_k"},"source":["## Installing Packages and Setting Up GPU"]},{"cell_type":"code","metadata":{"id":"xwjf3IQkhZnQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618943932264,"user_tz":240,"elapsed":8946,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"a3bad0c9-83ee-4b93-d164-5f1c0a757d62"},"source":["import torch\n","import torch.nn as nn\n","import torchtext\n","from torchtext import datasets\n","from torchtext.legacy import data\n","import re\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","import spacy \n","import math\n","import nltk\n","nltk.download('stopwords')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMEDSxEnKS8n","executionInfo":{"status":"ok","timestamp":1618943944165,"user_tz":240,"elapsed":8141,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"ca0818ca-31e7-4fa4-a370-9905b4a3413d"},"source":["!pip install wandb -qqq\n","import wandb"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.1MB 7.9MB/s \n","\u001b[K     |████████████████████████████████| 163kB 47.3MB/s \n","\u001b[K     |████████████████████████████████| 133kB 33.9MB/s \n","\u001b[K     |████████████████████████████████| 102kB 13.1MB/s \n","\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19u_sU9a9BC0","executionInfo":{"status":"ok","timestamp":1618943948782,"user_tz":240,"elapsed":433,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"87e786e1-9e88-41a0-84d3-2dc5d1361391"},"source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n"," \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)   \n","\n","device=get_default_device()\n","device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"Ihd_wxFVEJ_J"},"source":["## Loading Data"]},{"cell_type":"code","metadata":{"id":"Wth4dccFhb0Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618944192228,"user_tz":240,"elapsed":240521,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"3926b4db-8ab5-42ca-fc7c-cd80d6880f01"},"source":["#Glove files\n","glove = torchtext.vocab.GloVe(name='6B',dim=300)\n","\n","print(glove.vectors.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":[".vector_cache/glove.6B.zip: 862MB [02:49, 5.08MB/s]                           \n","100%|█████████▉| 399884/400000 [00:37<00:00, 10490.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([400000, 300])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d4M5mXMNht3c","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1618944209227,"user_tz":240,"elapsed":3199,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"c4b4a3c8-b530-4f70-a6c2-d5c3e21beeda"},"source":["#Sentiment files \n","# 2 Class from https://github.com/clairett/pytorch-sentiment-classification\n","colnames=['review', 'sentiment'] \n","train=pd.read_csv(drive_folder+\"data/SST2/train.tsv\", sep = '\\t', names=colnames, header=None)\n","dev=pd.read_csv(drive_folder+\"data/SST2/dev.tsv\", sep = '\\t', names=colnames, header=None)\n","test=pd.read_csv(drive_folder+\"data/SST2/test.tsv\", sep = '\\t', names=colnames, header=None)\n","\n","dev.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one long string of cliches</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>if you 've ever entertained the notion of doin...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>k 19 exploits our substantial collective fear ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>it 's played in the most straight faced fashio...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>there is a fabric of complex ideas here , and ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0                         one long string of cliches          0\n","1  if you 've ever entertained the notion of doin...          0\n","2  k 19 exploits our substantial collective fear ...          0\n","3  it 's played in the most straight faced fashio...          0\n","4  there is a fabric of complex ideas here , and ...          1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"aZYkgoIzEQGv"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"jZVPocnohyC4","executionInfo":{"status":"ok","timestamp":1618944214317,"user_tz":240,"elapsed":1287,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}}},"source":["#Expanding contractions (pulled from other code)\n","contraction_dict = {\n","    \"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\",\n","    \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n","    \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n","    \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n","    \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n","    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\",\n","    \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n","    \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\",\n","    \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n","    \"i'll\": \"i will\",  \"i'll've\": \"i will have\", \"i'm\": \"i am\",\n","    \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n","    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n","    \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n","    \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\",\n","    \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n","    \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n","    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n","    \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n","    \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n","    \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n","    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n","    \"so's\": \"so as\", \"this's\": \"this is\", \"that'd\": \"that would\",\n","    \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n","    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n","    \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n","    \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n","    \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n","    \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n","    \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n","    \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n","    \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n","    \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n","    \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n","    \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n","    \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n","    \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n","    \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n","    \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n","    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n","    \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"\n","}\n","\n","def clean_contractions(text, contraction_dict):\n","    specials = [\"’\", \"‘\", \"´\", \"`\"]\n","    for s in specials:\n","        text = text.replace(s, \"'\")\n","    text = ' '.join([contraction_dict[t] if t in contraction_dict else t for t in text.split(\" \")])\n","    return text\n","\n","punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n","punct_dict = {\n","    \"‘\": \"'\",    \"₹\": \"e\",      \"´\": \"'\", \"°\": \"\",         \"€\": \"e\",\n","    \"™\": \"tm\",   \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\",        \"—\": \"-\",\n","    \"–\": \"-\",    \"’\": \"'\",      \"_\": \"-\", \"`\": \"'\",        '“': '\"',\n","    '”': '\"',    '“': '\"',      \"£\": \"e\", '∞': 'infinity', 'θ': 'theta',\n","    '÷': '/',    'α': 'alpha',  '•': '.', 'à': 'a',        '−': '-',\n","    'β': 'beta', '∅': '',       '³': '3', 'π': 'pi'\n","}\n","def clean_special_chars(text, punct, punct_dict):\n","    for p in punct_dict:\n","        text = text.replace(p, punct_dict[p])\n","    \n","    for p in punct:\n","        text = text.replace(p, f' {p} ')\n","    \n","    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that have to be dealt with in last\n","    for s in specials:\n","        text = text.replace(s, specials[s])\n","    \n","    return text\n","\n","\n","stopwords = nltk.corpus.stopwords.words('english')\n","\n","def preprocess_text(text, contraction_dict, punct, punct_dict):\n","    clean_text=text.lower()\n","    clean_text=clean_contractions(clean_text, contraction_dict)\n","    clean_text=clean_special_chars(clean_text, punct, punct_dict)\n","    clean_text=re.split('\\W+', clean_text)\n","    clean_text=[token for token in clean_text if token not in stopwords]  \n","    return \" \".join(clean_text)\n","\n","preprocess_text(\"samhdbei. 2345324@@# !~~~ sdne @ dsecwAADEk. SDKM\",contraction_dict, punct, punct_dict)\n","\n","nlp = spacy.load('en', disable=['parser','tagger','ner'])\n","\n","def tokenizer(s):\n","    return [w.text.lower() for w in nlp(preprocess_text(s,contraction_dict, punct, punct_dict))]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Io0RoRXc7hv4","executionInfo":{"status":"ok","timestamp":1618944553892,"user_tz":240,"elapsed":335385,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"35817643-98e2-4843-aa8c-84081d4f53c2"},"source":["#Connecting GloVe and SST together --> tensor batch size x review length \n","\n","TEXT = torchtext.legacy.data.Field(tokenize = tokenizer)\n","LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)\n","\n","#Reading again using tabular dataset\n","datafields=[('review', TEXT),('sentiment', LABEL)]\n","trn,val,tst=torchtext.legacy.data.TabularDataset.splits(path=drive_folder+\"data/SST2/\", train='train.tsv', validation='dev.tsv', test='test.tsv',format='tsv',skip_header=False, fields=datafields)\n","\n","#Including ony top 30000 words from vocab, building vocab for train data \n","# Extracting these words from glove embeddings i.e. unique ids representing words should come from glove\n","TEXT.build_vocab(trn,max_size=30000,vectors='glove.6B.300d', unk_init=torch.Tensor.normal_)\n","LABEL.build_vocab(trn)\n","\n","#Fix mappings (because they are currently backwards, see next cell)\n","LABEL.vocab.stoi\n","\n","#Loop through trn and get a minibatch to work with \n","train_iterator,test_iterator, val_iterator=torchtext.legacy.data.BucketIterator.splits((trn,tst,val),batch_sizes=(10,10,10),sort_key =lambda x: len(x.review), sort_within_batch=False, device=device)\n","print(len(train_iterator))# train batches\n","print(len(val_iterator))# val batches"],"execution_count":8,"outputs":[{"output_type":"stream","text":["692\n","88\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tahHqo6STXwh","executionInfo":{"status":"ok","timestamp":1618944574867,"user_tz":240,"elapsed":405,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"d795500e-acce-4299-d1e4-abaa34e5f924"},"source":["LABEL.vocab.stoi"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["defaultdict(None, {'0': 1, '1': 0})"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7a2jTcm9Ep4","executionInfo":{"status":"ok","timestamp":1618944588211,"user_tz":240,"elapsed":11996,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"6b34de7b-053c-49e7-c711-2a9d4510085c"},"source":["#Checking out our batches\n","def show_batch(dl):\n","    for reviews, sentiments in dl:\n","        print(reviews.T.shape)\n","        print(sentiments.shape)\n","        print(sentiments)\n","        break\n","        \n","show_batch(train_iterator)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["torch.Size([10, 18])\n","torch.Size([10])\n","tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0.], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qCfwR0fGHpe8"},"source":["# Building Model"]},{"cell_type":"code","metadata":{"id":"9AhXBclth5pe","executionInfo":{"status":"ok","timestamp":1618944595747,"user_tz":240,"elapsed":346,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}}},"source":["class BiLSTM(nn.Module):\n","    \n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n","                 output_dim, n_layers, bidirectional, batch_first, dropout):\n","        \n","        super(BiLSTM, self).__init__()\n","        \n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim) # Convert sparse 1 hot encoded vectors to embeddings (glove embedding will be used here)\n","        \n","        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim,\n","                            num_layers=n_layers, batch_first=batch_first,\n","                            dropout=dropout, bidirectional=bidirectional)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","        \n","    def forward(self, text):\n","\n","      embedded = self.embedding(text)\n","\n","      embedded = self.dropout(embedded)\n","\n","      _, (hidden, _) = self.lstm(embedded)\n","\n","      #Final hidden from going left/right and concatenating\n","      hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)  # shape of hidden before concatenation: 4x10x100\n","\n","      output = self.fc(hidden) \n","\n","      #Option 1\n","      # Uses cross entropy loss, which will apply softmax during training, as our criterion \n","      return output\n","\n","      #Option 2\n","      # Allows us to calculate cross entropy loss by hand (i.e. perform softmax here and then calculate mean loss during training)\n","      #return torch.log_softmax(output, dim=-1) #this allows us to calculate cross-entropy by hand by doing the softmax here and then calculating the mean loss during training\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q50-DL00IGQZ"},"source":["# Setting Parameters"]},{"cell_type":"code","metadata":{"id":"mi3zrOZlvbJq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618946671308,"user_tz":240,"elapsed":314,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"8707ba79-fee1-41db-ba75-9f138452e29c"},"source":["#Setting configurations and instantiating model\n","vocab_size = len(TEXT.vocab)\n","embedding_dim = 300\n","hidden_dim = 100\n","output_dim =  2\n","n_layers = 2\n","bidirectional = True\n","dropout = 0.5\n","batch_first=True\n","\n","model = BiLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, batch_first, dropout)\n","model.cuda()"],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BiLSTM(\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (embedding): Embedding(13688, 300)\n","  (lstm): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (fc): Linear(in_features=200, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"rFyH-l2VIJWM","executionInfo":{"status":"ok","timestamp":1618946747513,"user_tz":240,"elapsed":307,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}}},"source":["#Optimizer \n","\n","#Option 1: SGD\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.0002) # Based on class code\n","\n","#Option 2: Adam \n","#lr=np.linspace(0.0001, 0.01, 10) # Grid search (not implemented yet)\n","#optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=10e-6) # Based on Bastings et al. 2020\n","#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=10e-6) # Our choice for best train loss (change hidden_dim to 100)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=10e-6) # Our choice for best val loss"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Wl7o-jEIKeE","executionInfo":{"status":"ok","timestamp":1618946749449,"user_tz":240,"elapsed":351,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}}},"source":["#Criterion\n","criterion = nn.CrossEntropyLoss()"],"execution_count":132,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bvPYmAzCXBq","executionInfo":{"status":"ok","timestamp":1618946750360,"user_tz":240,"elapsed":406,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"29f7d8e3-dc62-40f1-dbe6-c2573c67d65d"},"source":["#Attaching embeddings \n","pretrained_embeddings = TEXT.vocab.vectors\n","print(pretrained_embeddings.shape)\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings)\n","\n","unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n","pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n","model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n","\n","#print(model.embedding.weight.data)"],"execution_count":133,"outputs":[{"output_type":"stream","text":["torch.Size([13688, 300])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"us4kZn8rINAg"},"source":["# Training Model"]},{"cell_type":"code","metadata":{"id":"H7kZrGt55WEq","executionInfo":{"status":"ok","timestamp":1618945508649,"user_tz":240,"elapsed":214,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}}},"source":["#Train\n","def train(model, iterator, criterion, optimizer):\n","    \n","  epoch_loss = 0\n","\n","  model.train()\n","\n","  for batch in iterator:\n","        \n","      optimizer.zero_grad()\n","        \n","      #Option 1: (see BiLSTM class for description)\n","      predictions = model(batch.review.T).squeeze(1)\n","      loss = criterion(predictions,batch.sentiment.long())\n","\n","      #Option 2: (see BiLSTM class for description) \n","      #predictions = model(batch.review.T).squeeze(1)\n","      #loss = -torch.index_select(predictions, 1, batch.sentiment.long()).mean() \n","        \n","      loss.backward()\n"," \n","      optimizer.step()\n","        \n","      epoch_loss += loss.item()\n","\n","  return epoch_loss"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"gSmQRHFb8TJV","executionInfo":{"status":"ok","timestamp":1618945511489,"user_tz":240,"elapsed":360,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}}},"source":["#Validation\n","\n","def evaluate(model, iterator, criterion):\n","    \n","    #Initialize every epoch\n","    epoch_loss = 0\n","\n","    #Deactivate dropout layers\n","    model.eval()\n","    \n","    #Deactivate autograd\n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            #Do the predictions  \n","            predictions = model(batch.review.T).squeeze(1)\n","            \n","            #Compute loss and accuracy\n","            loss = criterion(predictions,batch.sentiment.long())\n","            \n","            #Keep track of loss and accuracy\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DDeKmaac_3Sh","executionInfo":{"status":"ok","timestamp":1618946805876,"user_tz":240,"elapsed":47316,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"80c28f6a-c944-40b0-dfe7-21673ad59263"},"source":["#Comparing train/val in 10 epochs\n","\n","N_EPOCHS = 10\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","     \n","    #Train the model\n","    train_loss = train(model, train_iterator, criterion, optimizer)\n","    \n","    #Evaluate the model\n","    valid_loss = evaluate(model, val_iterator, criterion)\n","    \n","    #Save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'model.pth')\n","    \n","    print(f'\\tTrain Loss: {train_loss:.3f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f}%')"],"execution_count":134,"outputs":[{"output_type":"stream","text":["\tTrain Loss: 594.079%\n","\t Val. Loss: 0.710%\n","\tTrain Loss: 496.866%\n","\t Val. Loss: 0.635%\n","\tTrain Loss: 438.601%\n","\t Val. Loss: 0.590%\n","\tTrain Loss: 410.894%\n","\t Val. Loss: 0.560%\n","\tTrain Loss: 381.882%\n","\t Val. Loss: 0.541%\n","\tTrain Loss: 375.604%\n","\t Val. Loss: 0.529%\n","\tTrain Loss: 374.197%\n","\t Val. Loss: 0.519%\n","\tTrain Loss: 358.005%\n","\t Val. Loss: 0.513%\n","\tTrain Loss: 355.716%\n","\t Val. Loss: 0.508%\n","\tTrain Loss: 344.606%\n","\t Val. Loss: 0.504%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8JZTrxjmIQPz"},"source":["# Testing Model"]},{"cell_type":"code","metadata":{"id":"HTa_cG6XZ2ug","executionInfo":{"status":"ok","timestamp":1618946834032,"user_tz":240,"elapsed":494,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}}},"source":["#Test\n","with torch.no_grad():\n","  acc=0\n","  acc_score=0\n","  iterator_len=0\n","  for batch in test_iterator:\n","    pred = model(batch.review.T)\n","    y_hat = torch.sigmoid(pred) # Turn into probabilities\n","    y_hat = torch.argmax(y_hat,dim=1)\n","    acc=torch.where(y_hat==batch.sentiment, 1, 0).sum()\n","    acc_score = acc_score + acc\n","\n","acc_score=100*acc_score/(10*len(test_iterator))"],"execution_count":135,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XI2lak_r5gnf","executionInfo":{"status":"ok","timestamp":1618946835653,"user_tz":240,"elapsed":434,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"0566c1a8-fcf1-40b4-d272-d5db188b53e7"},"source":["print(acc_score)"],"execution_count":136,"outputs":[{"output_type":"stream","text":["tensor(76.6667, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Okk_OqXgKaiI"},"source":["# Weights and Biases: Visualization of Loss"]},{"cell_type":"markdown","metadata":{"id":"mmtw6fnuOfBH"},"source":["This is a duplication of the code that trains our model. It takes the section of code that runs through our training/validation loops and visualizes the loss over the number of epochs we specify.  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602},"id":"2y12dVb6KdUW","executionInfo":{"status":"error","timestamp":1618946950952,"user_tz":240,"elapsed":86301,"user":{"displayName":"Linda Wang","photoUrl":"","userId":"11515571842830147609"}},"outputId":"9a832ed1-9697-49e4-c7bc-74be59d9fdcf"},"source":["run = wandb.init(project=\"Replication\",\n","            \n","           config={\n","               \"epoch\": 10,\n","           })\n","\n","run.watch(model)\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(run.config.epoch):\n","     \n","    #Train the model\n","    train_loss = train(model, train_iterator, criterion, optimizer)\n","    \n","    #Evaluate the model\n","    valid_loss = evaluate(model, val_iterator, criterion)\n","    \n","    #Save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'model.pth')\n","    \n","    run.log(dict(loss=train_loss, epoch=epoch))\n","\n","run.finish()\n","run"],"execution_count":137,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-137-65a9d08dc9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            config={\n\u001b[0;32m----> 4\u001b[0;31m                \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m            })\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_noop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_warning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# apply updated global state after login was handled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, _backend, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;31m# make sure login credentials get to the backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mno_offline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mno_create\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         )\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 )\n\u001b[1;32m    136\u001b[0m             )\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_ask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mwrite_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}